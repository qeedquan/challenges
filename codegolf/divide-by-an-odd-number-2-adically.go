/*

Given a and b, both odd n+1-bit integers, compute a/b to a precision of n+1 bits in the 2-adic integers.
That is, compute c such that a=bc(mod2n+1).
n should be your language's native integer size, or if native integers are bigints, take it as a parameter.
If your language uses trits (and presumably is either Setun assembly, TriINTERCAL, or Malbolge),
you may instead compute in the 3-adics, in which case a and b should be multiples of 3 plus 1.

Inputs should be (a−1)/2 and (b−1)/2 (trits: (x−1)/3).

This is code-golf, so shortest answer in bytes (per language) wins.

Test cases:

All test cases are truncatable; if the last n bits match the inputs, the last n bits of the outputs match.
Test cases (in hex, 32bit): (apologies for poor vinculum placement)

|  (a-1)/2  |  (b-1)/2  | (a/b-1)/2 |
|-----------+-----------+-----------|
| …00000000 | …00000001 | …55555555 | (1/3 = A̅B)
| …00000000 | …00000002 | …66666666 | (1/5 = C̅D)
| …00000001 | …00000002 | …33333333 | (3/5 = 6̅7)
| …00000000 | …00000003 | …DB6DB6DB | (1/7 = 6̅D̅B̅7)
| …FFFFFFFF | …00000003 | …24924924 | (-1/7 = 2̅4̅9̅)
| …4620BA27 | …1876DCBC | …48CAF903 | (random)
More test cases may be generated by multiplying random n+1-bit odd integers and taking the last n+1 bits of the result (then shifting right by 1).

A few test cases for ternary computers (nonary this time):

|  (a-1)/3  |  (b-1)/3  | (a/b-1)/3 |
|-----------+-----------+-----------|
| …00000000 | …00000002 | …51251251 | (1/7 = 3̅7̅6̅4)
| …23472148 | …12435871 | …65732854 | (random again)

Similarly, do the same with n+1-trit integers ending with a 1 trit.

*/

package main

import (
	"fmt"
	"math/bits"
)

func main() {
	fmt.Printf("%#x\n", div2p(0, 1))
	fmt.Printf("%#x\n", div2p(0, 2))
	fmt.Printf("%#x\n", div2p(1, 2))
	fmt.Printf("%#x\n", div2p(0, 3))
	fmt.Printf("%#x\n", div2p(^uint(0), 3))
	fmt.Printf("%#x\n", div2p(0x4620ba27, 0x1876dcbc))
}

/*

@Daniel Schepler

Explanation: since (2b+1)(2c+1)=2(2bc+b+c)+1 should end up equal to 2a+1, we want to find a root of f(c)=2bc+b+c−a.
We do so using Newton's method (as in the proof of Hensel's lemma), with the optimization that f′(c)=2b+1≡1(mod2),
so it suffices to divide by 1 instead of by f′(c).
So, we iterate to find a fixed point of c↦c−f(c)1=a−b−2bc.
(And since each iteration increases the number of correct binary digits by at least one, and we are working with 32-bit integers, then 32 iterations suffices.)

Note that it's interesting we do not need to initialize c to any particular starting value, since whatever the starting value is, we converge to the unique fixed point anyway.

*/

func div2p(a, b uint) uint {
	c := uint(0)
	for i := bits.UintSize; i > 0; i-- {
		c = a - b - 2*b*c
	}
	return c
}
